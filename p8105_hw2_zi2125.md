Homework 2
================
Zaynub Ibrahim

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(dplyr)
```

## Problem 1

Read the Mr.Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected including some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

In 2018, the total precipitation was 70.33.

In 2017, the median number of sports balls in a dumpster was 8.

## Problem 2

Read the NYC Transit dataset. Clean data, retain specific variables, and
convert variable entry from character to logic.

``` r
transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
      janitor::clean_names() %>%
   select(line:entry, vending, ada) %>%
   mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE")
   )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains 1868 observations with 1868 rows and 19 columns.
Variables contained in this dataset are line, station\_name,
station\_latitude, station\_longitude, route1, route2, route3, route4,
route5, route6, route7, route8, route9, route10, route11,
entrance\_type, entry, vending, ada. The cleaning steps taken so far
include changing variable names to snake case, keeping only specific
variables using the select function, and changing the entry variable
from a character variable to a logical variable using the mutate
function.

However, despite this cleaning, the data is not tidy yet since each
route is its own variable and some are listed as character variable
while others are double vector variables. We need to convert them all to
character and then merge into one variable to make it easier to work
with, using the pivot\_longer function.

``` r
transit_tidy = transit_data %>%
  mutate( 
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
    ) 

transit_tidy = 
  pivot_longer(
    transit_tidy, 
    route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = "route"
    )
```

This tidy dataset contains 20548 observations with 20548 rows and 10
columns. Variables contained in this dataset are line, station\_name,
station\_latitude, station\_longitude, entrance\_type, entry, vending,
ada, route\_number, route\_name.

In this dataset, there are 465 distinct stations. Among theses, 84 are
ADA compliant. The proportion of station entrances and exits without
vending that allow entrance are 0.3770492.

There are 60 distinct stations that seve the A train and there are 17
distinct stations that both serve the A train and are ADA compliant.

## Problem 3

*Clean the pols-month.csv dataset.* Separate the mon variable into three
new variables labeled year, month, and day. Create a new president
variable and remove prez\_gop, prez\_dem, and day variables.

``` r
pols_month = read_csv(file = "./data/pols-month.csv") %>%
      janitor::clean_names() %>% 
    separate(
      mon,
      c("year", "month", "day")) %>% 
    mutate(
      month = month.name[as.factor(month)],
      year = as.factor(year),
      president = case_when(
        prez_gop == 1 ~ "gop",
        prez_dem == 1 ~ "dem")) %>%
      select(
        -c(prez_dem, prez_gop, day)) %>%
    relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

*Clean the snp.csv dataset* Separate the date into month and year,
change variable types, remove day variable.

``` r
snp = read_csv(file = "./data/snp.csv") %>%
      janitor::clean_names() %>% 
    separate(
      date,
      c("year", "month", "day")) %>% 
    mutate(
      month = month.name[as.factor(month)],
      year = as.factor(year)) %>% 
    select (-c(day)) %>%   
    relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

*Tidy the unemployment data*

``` r
unemployment= read_csv(file = "./data/unemployment.csv") %>%
      janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
unemployment = 
  pivot_longer(
    unemployment, 
    jan:dec,
    names_to = "month",
    values_to = "perc_unemployed",
    )
```
